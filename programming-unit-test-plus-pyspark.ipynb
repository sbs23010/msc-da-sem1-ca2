{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883d04a9",
   "metadata": {},
   "source": [
    "# Unit-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce462fe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T21:50:03.398828Z",
     "start_time": "2023-05-24T21:50:03.389822Z"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from unittest.mock import patch\n",
    "import datetime\n",
    "\n",
    "# Importing custom defined functions that need to be tested\n",
    "from myutils import perform_regression, \\\n",
    "    get_important_features_with_lasso, \\\n",
    "    get_param_grid, get_selected_features, \\\n",
    "    get_model_visualization_results, \\\n",
    "    extract_reply_body, \\\n",
    "    get_cleaned_data, \\\n",
    "    classify_sia_polarity, \\\n",
    "    classify_textblob_polarity, \\\n",
    "    predict_sentiment, \\\n",
    "    get_sentiment, \\\n",
    "    convert_quarter_to_dt, \\\n",
    "    cast_to_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2be4f9c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T21:52:54.100933Z",
     "start_time": "2023-05-24T21:52:54.073575Z"
    }
   },
   "outputs": [],
   "source": [
    "class RegressionTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Prepare a sample dataset for testing\n",
    "        self.df = pd.DataFrame({\n",
    "            'feature1': np.random.rand(100),\n",
    "            'feature2': np.random.rand(100),\n",
    "            'feature3': np.random.rand(100),\n",
    "            'feature4': np.random.rand(100),\n",
    "            'feature5': np.random.rand(100),\n",
    "            'target': np.random.rand(100)\n",
    "        })\n",
    "        self.X = self.df.iloc[:, :-1]\n",
    "        self.y = self.df['target']\n",
    "    \n",
    "    def test_perform_regression(self):\n",
    "        # Create an instance of the model\n",
    "        model = LinearRegression()\n",
    "        \n",
    "        # Perform regression. It takes 3 args, and returns list of 3 values: model, train_score and test_score\n",
    "        result = perform_regression(model, self.X, self.y)\n",
    "        \n",
    "        # Assert that the result is a list with three elements\n",
    "        self.assertIsInstance(result, list)\n",
    "        self.assertEqual(len(result), 3)\n",
    "        \n",
    "        # Assert that the first element is the model object\n",
    "        self.assertIsInstance(result[0], LinearRegression)\n",
    "        \n",
    "        # Assert that the second and third elements are floating-point values between 0 and 1\n",
    "        self.assertIsInstance(result[1], float)\n",
    "        self.assertIsInstance(result[2], float)\n",
    "        self.assertGreaterEqual(result[1], 0)\n",
    "        self.assertLessEqual(result[1], 1)\n",
    "#         self.assertGreaterEqual(result[2], 0)  # Negative Test score was returned occasionally\n",
    "        self.assertLessEqual(result[2], 1)\n",
    "        \n",
    "    def test_get_important_features_with_lasso(self):\n",
    "        # Call the function to get the ordered features\n",
    "        ordered_features_length = len(get_important_features_with_lasso(self.X, self.y))      \n",
    "        expected_features_length = 5\n",
    "        \n",
    "        # Assert the number ordered features match the length of expected features\n",
    "        self.assertEqual(ordered_features_length, expected_features_length)\n",
    "        \n",
    "    def test_get_param_grid(self):\n",
    "        param_grid = get_param_grid(RandomForestClassifier())\n",
    "        \n",
    "        # Assert that the param_grid is a dict\n",
    "        self.assertIsInstance(param_grid, dict)\n",
    "        \n",
    "    def test_get_selected_features(self):\n",
    "        ordered_features = get_important_features_with_lasso(self.X, self.y)\n",
    "        df = get_selected_features(self.X, ordered_features, 'Top 5')\n",
    "        \n",
    "        # Assert that the returned variable is Pandas DF, and has same no. of columns as requested\n",
    "        self.assertIsInstance(df, pd.DataFrame)\n",
    "        self.assertEqual(df.shape[1], 5)\n",
    "        \n",
    "    def test_get_model_visualization_results(self):\n",
    "        # Adding 5 more columns because the function expects the passed DF has 5 dependent variables\n",
    "        quarters = []\n",
    "        for year in np.arange(1998, 2023):\n",
    "            for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "                quarters.append(f'{year}{q}')\n",
    "        self.df['Quarter'] = quarters\n",
    "        for i in range(5):\n",
    "            self.df[f'target{i}'] = np.random.rand(100)\n",
    "            \n",
    "        # Call the function with all required arguments\n",
    "        hvplot_fig = get_model_visualization_results(self.df, LinearRegression(), None, False, 'All')\n",
    "        \n",
    "        # Assert that the returned value is a Holoviews layout\n",
    "        self.assertIsInstance(hvplot_fig, hv.Layout)\n",
    "        \n",
    "    # For function extract_reply_body(), single comment\n",
    "    def test_extract_reply_body_single_comment(self):\n",
    "        reply = {\n",
    "            'kind': 't1',\n",
    "            'data': {\n",
    "                'created': '2023-05-23',\n",
    "                'author': 'sajjan',\n",
    "                'link_id': 't3_postid',\n",
    "                'subreddit': 'ireland',\n",
    "                'body': 'First comment'\n",
    "            }\n",
    "        }\n",
    "        expected_result = {\n",
    "            'created_utc': '2023-05-23',\n",
    "            'author': 'sajjan',\n",
    "            'post_id': 'postid',\n",
    "            'subreddit': 'ireland',\n",
    "            'text': 'First comment'\n",
    "        }\n",
    "        result = extract_reply_body(reply)\n",
    "        self.assertEqual(result, expected_result)\n",
    "    \n",
    "    # For function extract_reply_body(), listing of replies\n",
    "    def test_extract_reply_body_listing(self):\n",
    "        reply = {\n",
    "            'kind': 'Listing',\n",
    "            'data': {\n",
    "                'children': [\n",
    "                    {\n",
    "                        'kind': 't1',\n",
    "                        'data': {\n",
    "                            'created': '2023-05-24',\n",
    "                            'author': 'john',\n",
    "                            'link_id': 't3_postid',\n",
    "                            'subreddit': 'unitedkingdom',\n",
    "                            'body': 'Reply number 1'\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        'kind': 't1',\n",
    "                        'data': {\n",
    "                            'created': '2023-05-24',\n",
    "                            'author': 'joe',\n",
    "                            'link_id': 't3_postid',\n",
    "                            'subreddit': 'netherlands',\n",
    "                            'body': 'Reply number 2'\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        expected_result = [\n",
    "            {\n",
    "                'created_utc': '2023-05-24',\n",
    "                'author': 'john',\n",
    "                'post_id': 'postid',\n",
    "                'subreddit': 'unitedkingdom',\n",
    "                'text': 'Reply number 1'\n",
    "            },\n",
    "            {\n",
    "                'created_utc': '2023-05-24',\n",
    "                'author': 'joe',\n",
    "                'post_id': 'postid',\n",
    "                'subreddit': 'netherlands',\n",
    "                'text': 'Reply number 2'\n",
    "            }\n",
    "        ]\n",
    "        result = extract_reply_body(reply)\n",
    "        self.assertEqual(result, expected_result)\n",
    "        \n",
    "    def test_get_cleaned_data(self):\n",
    "        cleaned_data = get_cleaned_data(pd.Series(\"Hello! Python unittest is great!\"))\n",
    "        expected_data = 'hello python unittest great'\n",
    "        \n",
    "        # Assert that the returned variable is Pandas Series\n",
    "        self.assertIsInstance(cleaned_data, pd.Series)\n",
    "        # Assert that the first item of array is same as expected value\n",
    "        self.assertEqual(cleaned_data.values[0], expected_data)\n",
    "        \n",
    "    def test_classify_textblob_polarity(self):\n",
    "        sentiment = classify_textblob_polarity(-0.3)\n",
    "        self.assertEqual(sentiment, 'negative')\n",
    "        \n",
    "    def test_classify_sia_polarity(self):\n",
    "        polarity = classify_sia_polarity({'compound': 0.75})\n",
    "        self.assertEqual(polarity, 'positive')\n",
    "        \n",
    "        \n",
    "    @patch('myutils.SentimentIntensityAnalyzer')\n",
    "    def test_predict_sentiment(self, mock_analyzer):\n",
    "        mock_analyzer.return_value.polarity_scores.return_value = {'compound': 0.3}\n",
    "        result = predict_sentiment('hello python unittest great')\n",
    "        self.assertEqual(result, 'positive')\n",
    "        \n",
    "    def test_get_sentiment(self):\n",
    "        sentiment = get_sentiment('hello python unittest great')\n",
    "        self.assertEqual(sentiment, 'positive')\n",
    "        \n",
    "    def test_convert_quarter_to_dt(self):\n",
    "        result_dt = convert_quarter_to_dt('2022Q4')\n",
    "        self.assertIsInstance(result_dt, datetime.datetime)\n",
    "        self.assertEqual(result_dt, datetime.datetime(2022, 12, 30, 0, 0))\n",
    "        \n",
    "    def test_cast_to_float(self):\n",
    "        result = cast_to_float('100.5 s')\n",
    "        self.assertIsInstance(result, float)\n",
    "        self.assertEqual(result, 100.5)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b302ecf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T21:52:54.570468Z",
     "start_time": "2023-05-24T21:52:54.388990Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_cast_to_float (__main__.RegressionTest) ... ok\n",
      "test_classify_sia_polarity (__main__.RegressionTest) ... ok\n",
      "test_classify_textblob_polarity (__main__.RegressionTest) ... ok\n",
      "test_convert_quarter_to_dt (__main__.RegressionTest) ... ok\n",
      "test_extract_reply_body_listing (__main__.RegressionTest) ... ok\n",
      "test_extract_reply_body_single_comment (__main__.RegressionTest) ... ok\n",
      "test_get_cleaned_data (__main__.RegressionTest) ... ok\n",
      "test_get_important_features_with_lasso (__main__.RegressionTest) ... ok\n",
      "test_get_model_visualization_results (__main__.RegressionTest) ... ok\n",
      "test_get_param_grid (__main__.RegressionTest) ... ok\n",
      "test_get_selected_features (__main__.RegressionTest) ... ok\n",
      "test_get_sentiment (__main__.RegressionTest) ... ok\n",
      "test_perform_regression (__main__.RegressionTest) ... ok\n",
      "test_predict_sentiment (__main__.RegressionTest) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 14 tests in 0.173s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x16aaa03a0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], exit=False, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ffec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T18:17:53.329313Z",
     "start_time": "2023-05-24T18:17:53.321026Z"
    }
   },
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08dba6e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:45:28.020620Z",
     "start_time": "2023-05-25T08:45:28.005160Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = '/opt/homebrew/opt/apache-spark/libexec/'\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d9515e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:45:34.071870Z",
     "start_time": "2023-05-25T08:45:33.392540Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad4bfc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:45:47.557776Z",
     "start_time": "2023-05-25T08:45:39.721123Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up JAVA_TOOL_OPTIONS: -Dlog4j2.formatMsgNoLookups=true\n",
      "Picked up JAVA_TOOL_OPTIONS: -Dlog4j2.formatMsgNoLookups=true\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/25 09:45:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName('CA2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf142694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:45:51.415135Z",
     "start_time": "2023-05-25T08:45:51.023857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://ec.europa.eu/eurostat/web/products-datasets/-/teiis500\n",
    "url = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/teiis500?format=TSV\"\n",
    "res = requests.get(url)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc68b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:46:31.561505Z",
     "start_time": "2023-05-25T08:46:21.466388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|freq,indic_bt,nace_r2,unit,geo\\TIME_PERIOD|2022-04 |2022-05 |2022-06 |2022-07 |2022-08 |2022-09 |2022-10 |2022-11 |2022-12 |2023-01 |2023-02 |2023-03 |\n",
      "+------------------------------------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|                      M,PROD,F,I2015_SC...|  134.1 |  133.5 |  130.4 |  128.7 |  130.1 |  129.1 |  130.0 |  132.3 |  128.8 |  133.3 |  146.2 | 130.3 p|\n",
      "|                      M,PROD,F,I2015_SC...|   98.8 |   99.4 |   98.7 |  100.5 |   99.1 |   98.1 |   98.3 |   99.9 |   99.3 |   97.9 |  100.6 |   98.4 |\n",
      "|                      M,PROD,F,I2015_SC...|   89.9 |   91.8 |   90.4 |   89.9 |   90.2 |   90.0 |   90.6 |   90.9 |   89.4 |   89.8 |   89.5 |  90.2 p|\n",
      "|                      M,PROD,F,I2015_SC...|  112.7 |  109.9 |  109.4 |  105.9 |  107.5 |  105.5 |  108.5 |  108.4 |  108.2 |  113.6 |  109.3 |  108.3 |\n",
      "+------------------------------------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Pandas DF because unable to read CSV in PySpark from URL or StringIO\n",
    "eu_prod_construction_df = spark.createDataFrame(pd.read_csv(StringIO(res.text), delimiter='\\t'))\n",
    "eu_prod_construction_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e24d41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:46:43.079010Z",
     "start_time": "2023-05-25T08:46:40.734301Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(75, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the DF\n",
    "eu_prod_construction_df.count(), len(eu_prod_construction_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7958a78e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:46:56.188782Z",
     "start_time": "2023-05-25T08:46:46.791102Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/25 09:46:47 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+\n",
      "|summary|freq,indic_bt,nace_r2,unit,geo\\TIME_PERIOD|         2022-04 |         2022-05 |         2022-06 |         2022-07 |          2022-08 |          2022-09 |          2022-10 |         2022-11 |         2022-12 |          2023-01 |          2023-02 |         2023-03 |\n",
      "+-------+------------------------------------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+\n",
      "|  count|                                        75|               75|               75|               75|               75|                75|                75|                75|               75|               75|                75|                75|               75|\n",
      "|   mean|                                      null|38.60983606557377|40.57868852459017|38.82295081967212|38.16065573770492| 39.01475409836066|38.546551724137935|38.490909090909085|39.32545454545454|36.99038461538461| 41.73137254901961| 39.74038461538461|36.92666666666666|\n",
      "| stddev|                                      null|56.25124800072744|56.13368303955032|56.26638840800851|56.28130322670375|55.669745930997905| 56.61721644894865| 55.94988919569101|  56.293744202741|55.15669393757825|55.317695144306505|56.768782016297266|58.48719242843615|\n",
      "|    min|                      M,PROD,F,I2015_SC...|           -0.1 p|            -0.1 |            -0.1 |            -0.2 |            -0.2 p|             -0.2 |            -0.1 s|            -0.1 |            -0.2 |             -0.1 |             -0.1 |            -0.3 |\n",
      "|    max|                      M,PROD,F,PCH_M1_S...|            98.8 |            99.4 |            98.7 |            89.9 |             99.1 |             98.1 |             98.3 |            99.9 |            99.3 |            98.3 p|              9.7 |               : |\n",
      "+-------+------------------------------------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eu_prod_construction_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d85766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:47:04.241783Z",
     "start_time": "2023-05-25T08:46:57.497103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+\n",
      "|summary|freq,indic_bt,nace_r2,unit,geo\\TIME_PERIOD|         2022-04 |         2022-05 |         2022-06 |         2022-07 |          2022-08 |          2022-09 |          2022-10 |         2022-11 |         2022-12 |          2023-01 |          2023-02 |         2023-03 |\n",
      "+-------+------------------------------------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+\n",
      "|  count|                                        75|               75|               75|               75|               75|                75|                75|                75|               75|               75|                75|                75|               75|\n",
      "|   mean|                                      null|38.60983606557377|40.57868852459017|38.82295081967212|38.16065573770492| 39.01475409836066|38.546551724137935|38.490909090909085|39.32545454545454|36.99038461538461| 41.73137254901961| 39.74038461538461|36.92666666666666|\n",
      "| stddev|                                      null|56.25124800072744|56.13368303955032|56.26638840800851|56.28130322670375|55.669745930997905| 56.61721644894865| 55.94988919569101|  56.293744202741|55.15669393757825|55.317695144306505|56.768782016297266|58.48719242843615|\n",
      "|    min|                      M,PROD,F,I2015_SC...|           -0.1 p|            -0.1 |            -0.1 |            -0.2 |            -0.2 p|             -0.2 |            -0.1 s|            -0.1 |            -0.2 |             -0.1 |             -0.1 |            -0.3 |\n",
      "|    25%|                                      null|             -1.6|              0.3|             -0.7|             -0.2|               0.3|               0.2|               0.6|              0.3|             -1.7|               0.4|               0.3|             -3.4|\n",
      "|    50%|                                      null|              3.6|              5.2|              2.3|              2.0|               3.7|               1.5|               2.5|              2.7|              2.1|               5.2|               2.7|             -0.3|\n",
      "|    75%|                                      null|            104.4|            104.3|            102.9|            102.9|             101.1|             103.6|             104.7|            104.8|             99.3|             103.5|             100.6|            104.3|\n",
      "|    max|                      M,PROD,F,PCH_M1_S...|            98.8 |            99.4 |            98.7 |            89.9 |             99.1 |             98.1 |             98.3 |            99.9 |            99.3 |            98.3 p|              9.7 |               : |\n",
      "+-------+------------------------------------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eu_prod_construction_df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d79ca6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-25T08:47:12.035070Z",
     "start_time": "2023-05-25T08:47:11.082341Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Taking out country, and unit of measurement to separate columns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43meu_prod_construction_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcountry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfreq,indic_bt,nace_r2,unit,geo\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTIME_PERIOD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m      3\u001b[0m eu_prod_construction_df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m'\u001b[39m, col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq,indic_bt,nace_r2,unit,geo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTIME_PERIOD\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/opt/apache-spark/libexec/python/pyspark/sql/dataframe.py:2977\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   2945\u001b[0m \n\u001b[1;32m   2946\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   2975\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 2977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2978\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   2979\u001b[0m     )\n\u001b[1;32m   2980\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# Taking out country, and unit of measurement to separate columns\n",
    "eu_prod_construction_df.withColumn('country', col('freq,indic_bt,nace_r2,unit,geo\\TIME_PERIOD')).apply(lambda x: x.split(',')[4])\n",
    "eu_prod_construction_df.withColumn('stats', col('freq,indic_bt,nace_r2,unit,geo\\TIME_PERIOD')).apply(lambda x: x.split(',')[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3cffc",
   "metadata": {},
   "source": [
    "PySpark has several limitations in regards to syntax when compared to Pandas. To name few, it fails to read from URL without additional packages, and doesn't have apply() method. It would however do better for use cases involving larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf17f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
